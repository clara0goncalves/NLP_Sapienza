{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0sPER-ui9HA"
      },
      "source": [
        "# 1.0 Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83qtMqTUka4o",
        "outputId": "a7f9eb6c-a8c7-45f7-f874-463329d80341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langid in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.1.6)\n",
            "Requirement already satisfied: numpy in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langid) (1.26.0)\n",
            "Requirement already satisfied: gensim in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gensim) (1.26.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gensim) (1.11.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: spacy in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (2.28.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from spacy) (65.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (1.26.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jinja2->spacy) (2.1.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\runpy.py\", line 188, in _run_module_as_main\n",
            "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\runpy.py\", line 147, in _get_module_details\n",
            "    return _get_module_details(pkg_main_name, error)\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\runpy.py\", line 111, in _get_module_details\n",
            "    __import__(pkg_name)\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\spacy\\__init__.py\", line 13, in <module>\n",
            "    from . import pipeline  # noqa: F401\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\spacy\\pipeline\\__init__.py\", line 1, in <module>\n",
            "    from .attributeruler import AttributeRuler\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\spacy\\pipeline\\attributeruler.py\", line 8, in <module>\n",
            "    from ..language import Language\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\spacy\\language.py\", line 43, in <module>\n",
            "    from .pipe_analysis import analyze_pipes, print_pipe_analysis, validate_attrs\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\spacy\\pipe_analysis.py\", line 6, in <module>\n",
            "    from .tokens import Doc, Span, Token\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\spacy\\tokens\\__init__.py\", line 1, in <module>\n",
            "    from ._serialize import DocBin\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\spacy\\tokens\\_serialize.py\", line 14, in <module>\n",
            "    from ..vocab import Vocab\n",
            "  File \"spacy\\vocab.pyx\", line 1, in init spacy.vocab\n",
            "  File \"spacy\\tokens\\doc.pyx\", line 49, in init spacy.tokens.doc\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\spacy\\schemas.py\", line 287, in <module>\n",
            "    class TokenPattern(BaseModel):\n",
            "  File \"pydantic\\main.py\", line 299, in pydantic.main.ModelMetaclass.__new__\n",
            "  File \"pydantic\\fields.py\", line 411, in pydantic.fields.ModelField.infer\n",
            "  File \"pydantic\\fields.py\", line 342, in pydantic.fields.ModelField.__init__\n",
            "  File \"pydantic\\fields.py\", line 451, in pydantic.fields.ModelField.prepare\n",
            "  File \"pydantic\\fields.py\", line 545, in pydantic.fields.ModelField._type_analysis\n",
            "  File \"pydantic\\fields.py\", line 550, in pydantic.fields.ModelField._type_analysis\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\typing.py\", line 852, in __subclasscheck__\n",
            "    return issubclass(cls, self.__origin__)\n",
            "TypeError: issubclass() arg 1 must be a class\n",
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "x ./._s2v_old\n",
            "x ./s2v_old/\n",
            "x ./s2v_old/._freqs.json\n",
            "x ./s2v_old/freqs.json\n",
            "x ./s2v_old/._vectors\n",
            "x ./s2v_old/vectors\n",
            "x ./s2v_old/._cfg\n",
            "x ./s2v_old/cfg\n",
            "x ./s2v_old/._strings.json\n",
            "x ./s2v_old/strings.json\n",
            "x ./s2v_old/._key2row\n",
            "x ./s2v_old/key2row\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sense2vec in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.0.2)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sense2vec) (3.7.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.8.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sense2vec) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sense2vec) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sense2vec) (2.0.10)\n",
            "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sense2vec) (1.26.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (8.2.3)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (4.64.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (2.28.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (3.1.2)\n",
            "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (65.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (21.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (3.3.0)\n",
            "Requirement already satisfied: colorama>=0.4.6 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wasabi<1.2.0,>=0.8.1->sense2vec) (0.4.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from packaging>=20.0->spacy<4.0.0,>=3.0.0->sense2vec) (3.0.9)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->sense2vec) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->sense2vec) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->sense2vec) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (2022.9.24)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.0.0->sense2vec) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.0.0->sense2vec) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from typer<0.10.0,>=0.3.0->spacy<4.0.0,>=3.0.0->sense2vec) (8.1.3)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<4.0.0,>=3.0.0->sense2vec) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jinja2->spacy<4.0.0,>=3.0.0->sense2vec) (2.1.1)\n",
            "Requirement already satisfied: spacy_fastlang in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.1.0)\n",
            "Requirement already satisfied: fasttext-wheel<0.10.0,>=0.9.2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy_fastlang) (0.9.2)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy_fastlang) (3.7.4)\n",
            "Requirement already satisfied: pybind11>=2.2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from fasttext-wheel<0.10.0,>=0.9.2->spacy_fastlang) (2.12.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from fasttext-wheel<0.10.0,>=0.9.2->spacy_fastlang) (65.5.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from fasttext-wheel<0.10.0,>=0.9.2->spacy_fastlang) (1.26.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (4.64.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (2.28.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (3.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (21.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (3.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from packaging>=20.0->spacy<4.0.0,>=3.0.0->spacy_fastlang) (3.0.9)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy_fastlang) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy_fastlang) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy_fastlang) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy_fastlang) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy_fastlang) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy_fastlang) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy_fastlang) (2022.9.24)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.0.0->spacy_fastlang) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.0.0->spacy_fastlang) (0.1.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<4.0.0,>=3.0.0->spacy_fastlang) (0.4.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from typer<0.10.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy_fastlang) (8.1.3)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<4.0.0,>=3.0.0->spacy_fastlang) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jinja2->spacy<4.0.0,>=3.0.0->spacy_fastlang) (2.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langid\n",
        "!pip install gensim\n",
        "!pip install -U spacy\n",
        "!python -m spacy download it_core_news_sm\n",
        "!wget https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
        "!tar -xzvf s2v_reddit_2015_md.tar.gz\n",
        "!pip install sense2vec\n",
        "!pip install spacy_fastlang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-3BMXNIjGo0",
        "outputId": "4f4029be-8466-4362-9d69-eb3f50431962"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[29], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      5\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/gdrive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import re\n",
        "import json\n",
        "import gensim.downloader as api\n",
        "\n",
        "import langid\n",
        "from gensim.models import Word2Vec\n",
        "import spacy\n",
        "import spacy_fastlang\n",
        "\n",
        "from sense2vec import Sense2Vec\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from transformers import RobertaTokenizer\n",
        "from transformers import RobertaForMultipleChoice\n",
        "from torch.distributions import Categorical\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWomv2Y0g-l_"
      },
      "source": [
        "# 2.0 Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "M9yPG6KyH1dx"
      },
      "outputs": [],
      "source": [
        "def load_data(data_path, gold_path):\n",
        "  count = 0\n",
        "  hypernyms_dict = {}\n",
        "  with open(data_path, \"r\", encoding = 'utf-8') as data_file, open(gold_path, \"r\", encoding = 'utf-8') as gold_file:\n",
        "    for data_line, gold_line in zip(data_file, gold_file):\n",
        "      term_list = [term for term in data_line.split()[:-1]]\n",
        "      term = \" \".join(term_list)\n",
        "      hypernyms = [hypernym.replace(\"\\n\", \"\") for hypernym in gold_line.split(\"\\t\")]\n",
        "      hypernyms_dict[term] = hypernyms\n",
        "      count += 1\n",
        "\n",
        "      if count == 20:\n",
        "        break\n",
        "\n",
        "  return hypernyms_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "oWNvGVp9XdIx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#  PARTIAL italian training data\n",
        "train_hypernyms = load_data(\"/content/1B.italian.training.data.txt\", \"/content/1B.italian.training.gold.txt\")\n",
        "\n",
        "# PARTIAL italian test data\n",
        "test_hypernyms = load_data(\"/content/1B.italian.test.data.txt\", \"/content/1B.italian.test.gold.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff5gVEnfg6Lp"
      },
      "source": [
        "# 3.0 Find Distractors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SIts6mWLj_1"
      },
      "source": [
        "## 3.1 Fasttext\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHRYBJYpLpYi",
        "outputId": "12affec6-2bb2-425f-f3bd-0c1c250fbf15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'fastText' already exists and is not an empty directory.\n",
            "python3: can't open file '/content/setup.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "!cd fastText\n",
        "!sudo python setup.py install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVpKhfWuYzKN"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "K6SnidfZLq7S"
      },
      "outputs": [],
      "source": [
        "import fasttext.util\n",
        "# fasttext.util.download_model('it', if_exists='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xh530uT4Lwjn",
        "outputId": "a65e7903-4ede-4c6a-ae2d-64964387b926"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "model = fasttext.load_model('cc.it.300.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distractors for 'numero ordinale':\n",
            "1. dinale\n",
            "2. numeroe\n",
            "3. ordinal\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Define the find_distractors function with filtering for diminutives and augmentatives\n",
        "def find_distractors(word, num_distractors, model):\n",
        "    distractors = []\n",
        "\n",
        "    # Get the nearest neighbors of the word from the FastText model\n",
        "    nearest_neighbors = model.get_nearest_neighbors(word, k=num_distractors * 10)  # Fetch more neighbors to account for filtering\n",
        "\n",
        "    # Filter out diminutives and augmentatives, and ensure semantic relevance\n",
        "    for neighbor in nearest_neighbors:\n",
        "        candidate_word = neighbor[1]\n",
        "        # Filter out words with diminutive or augmentative suffixes\n",
        "        if not re.search(r'(ino|etto|ello|one|accio|astro)$', candidate_word):\n",
        "            # Ensure semantic relevance by measuring cosine similarity with target word\n",
        "            similarity = model.get_word_vector(word).dot(model.get_word_vector(candidate_word))\n",
        "            if similarity >= 0.1 and candidate_word != word:  # Adjust the threshold as needed\n",
        "                distractors.append(candidate_word)\n",
        "\n",
        "        if len(distractors) == num_distractors:\n",
        "            break\n",
        "\n",
        "    return distractors[:num_distractors]  # Return only the specified number of distractors\n",
        "\n",
        "# Define the word for which you want to find distractors\n",
        "word = \"numero ordinale\"\n",
        "\n",
        "import fasttext.util\n",
        "model = fasttext.load_model('cc.it.300.bin')\n",
        "distractors = find_distractors(word, 3, model)\n",
        "\n",
        "# Print the distractors\n",
        "print(\"Distractors for '{}':\".format(word))\n",
        "for i, distractor in enumerate(distractors, 1):\n",
        "    print(\"{}. {}\".format(i, distractor))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "training_data.txt cannot be opened for training!",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[74], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m new_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfine_tuned_model.bin\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Train a new FastText model using the combined vocabulary and the dimensionality of the existing model\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_supervised\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_data.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexisting_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dimension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrainedVectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexisting_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Save the new model\u001b[39;00m\n\u001b[0;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39msave_model(new_model_path)\n",
            "File \u001b[1;32mc:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\fasttext\\FastText.py:533\u001b[0m, in \u001b[0;36mtrain_supervised\u001b[1;34m(*kargs, **kwargs)\u001b[0m\n\u001b[0;32m    531\u001b[0m a \u001b[38;5;241m=\u001b[39m _build_args(args, manually_set_args)\n\u001b[0;32m    532\u001b[0m ft \u001b[38;5;241m=\u001b[39m _FastText(args\u001b[38;5;241m=\u001b[39ma)\n\u001b[1;32m--> 533\u001b[0m \u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m ft\u001b[38;5;241m.\u001b[39mset_args(ft\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mgetArgs())\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ft\n",
            "\u001b[1;31mValueError\u001b[0m: training_data.txt cannot be opened for training!"
          ]
        }
      ],
      "source": [
        "\n",
        "import fasttext\n",
        "\n",
        "# Load the existing FastText model\n",
        "existing_model_path = 'cc.it.300.bin'\n",
        "existing_model = fasttext.load_model(existing_model_path)\n",
        "\n",
        "# Extract vocabulary from the existing model\n",
        "existing_vocab = set(existing_model.words)\n",
        "\n",
        "# Load the new vocabulary\n",
        "new_vocabulary_path = 'vocabulary/1B.italian.vocabulary.txt'\n",
        "with open(new_vocabulary_path, 'r', encoding='utf-8') as f:\n",
        "    new_vocab = set(word.strip() for word in f)\n",
        "\n",
        "# Combine existing vocabulary with new vocabulary\n",
        "combined_vocab = existing_vocab.union(new_vocab)\n",
        "\n",
        "# Path to save the new model\n",
        "new_model_path = 'fine_tuned_model.bin'\n",
        "\n",
        "# Train a new FastText model using the combined vocabulary and the dimensionality of the existing model\n",
        "model = fasttext.train_supervised(input=\"training_data.txt\", dim=existing_model.get_dimension(), pretrainedVectors=existing_model_path)\n",
        "\n",
        "# Save the new model\n",
        "model.save_model(new_model_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "fine_tuned_model.bin cannot be opened for loading!",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[72], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m word \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumero ordinale\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfasttext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfine_tuned_model.bin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m distractors \u001b[38;5;241m=\u001b[39m find_distractors(word, \u001b[38;5;241m3\u001b[39m, model)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Print the distractors\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\fasttext\\FastText.py:441\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a model given a filepath and return a model object.\"\"\"\u001b[39;00m\n\u001b[0;32m    440\u001b[0m eprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_FastText\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\fasttext\\FastText.py:98\u001b[0m, in \u001b[0;36m_FastText.__init__\u001b[1;34m(self, model_path, args)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fasttext\u001b[38;5;241m.\u001b[39mfasttext()\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: fine_tuned_model.bin cannot be opened for loading!"
          ]
        }
      ],
      "source": [
        "# Define the word for which you want to find distractors\n",
        "word = \"numero ordinale\"\n",
        "\n",
        "import fasttext.util\n",
        "model = fasttext.load_model('fine_tuned_model.bin')\n",
        "distractors = find_distractors(word, 3, model)\n",
        "\n",
        "# Print the distractors\n",
        "print(\"Distractors for '{}':\".format(word))\n",
        "for i, distractor in enumerate(distractors, 1):\n",
        "    print(\"{}. {}\".format(i, distractor))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "1B.italian.vocabulary.txt cannot be opened for training!",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[70], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m training_data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1B.italian.vocabulary.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train the FastText model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_supervised\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_data_path\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\fasttext\\FastText.py:533\u001b[0m, in \u001b[0;36mtrain_supervised\u001b[1;34m(*kargs, **kwargs)\u001b[0m\n\u001b[0;32m    531\u001b[0m a \u001b[38;5;241m=\u001b[39m _build_args(args, manually_set_args)\n\u001b[0;32m    532\u001b[0m ft \u001b[38;5;241m=\u001b[39m _FastText(args\u001b[38;5;241m=\u001b[39ma)\n\u001b[1;32m--> 533\u001b[0m \u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m ft\u001b[38;5;241m.\u001b[39mset_args(ft\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mgetArgs())\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ft\n",
            "\u001b[1;31mValueError\u001b[0m: 1B.italian.vocabulary.txt cannot be opened for training!"
          ]
        }
      ],
      "source": [
        "import fasttext\n",
        "\n",
        "# Load your training data with the desired vocabulary\n",
        "training_data_path = '1B.italian.vocabulary.txt'\n",
        "\n",
        "# Train the FastText model\n",
        "model = fasttext.train_supervised(input=training_data_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhD8vekoRgIL"
      },
      "source": [
        "### Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYnIStdDL1Is",
        "outputId": "6b156975-5570-487f-a0ba-7feba2b9fec2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0.69635009765625, 'dinale'),\n",
              " (0.6637539267539978, 'tecnicoeconomica'),\n",
              " (0.6575295329093933, 'numeroe'),\n",
              " (0.6210983991622925, 'ordinal'),\n",
              " (0.617618203163147, 'Ordinale'),\n",
              " (0.6075699925422668, 'Numeroordinale'),\n",
              " (0.6015861630439758, 'Numerocardinale'),\n",
              " (0.5819660425186157, 'estetologo'),\n",
              " (0.5808798670768738, 'Sindacatore'),\n",
              " (0.5799951553344727, 'anticardinale')]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_nearest_neighbors('numero ordinale')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMYnnwyzL5n6",
        "outputId": "af942918-4bb0-4d08-e337-28e57ef7e214"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0.4903110861778259, 'decimillesimo'),\n",
              " (0.46558308601379395, 'millesimi'),\n",
              " (0.430698961019516, 'duecentesimo'),\n",
              " (0.4299042224884033, 'ordinalità'),\n",
              " (0.4258556365966797, 'centesimo'),\n",
              " (0.421135812997818, 'decimo'),\n",
              " (0.4166191816329956, 'trecentesimo'),\n",
              " (0.40764376521110535, 'decimillesimi'),\n",
              " (0.4020084738731384, 'cinquantesimo'),\n",
              " (0.40015530586242676, 'milionesimo')]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_analogies(\"numero ordinale\", \"carinale\", \"millesimo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "JUOTCo9WRzwu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distractors for 'numero ordinale':\n",
            "1. dinale\n",
            "2. tecnicoeconomica\n",
            "3. numeroe\n"
          ]
        }
      ],
      "source": [
        "word = \"numero ordinale\"\n",
        "distractors = find_distractors(word, 3, model)\n",
        "# Print the distractors\n",
        "print(\"Distractors for '{}':\".format(word))\n",
        "for i, distractor in enumerate(distractors, 1):\n",
        "    print(\"{}. {}\".format(i, distractor))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYZ0qhE8RkkU",
        "outputId": "70936007-18aa-4667-ca17-9b7117541c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distractor 1: dinale\n",
            "Cosine similarity: 0.7\n",
            "Distractor 2: tecnicoeconomica\n",
            "Cosine similarity: 0.66\n",
            "Distractor 3: numeroe\n",
            "Cosine similarity: 0.66\n"
          ]
        }
      ],
      "source": [
        "for i, distractor in enumerate(distractors):\n",
        "  print(f\"Distractor {i + 1}: {distractor}\")\n",
        "\n",
        "  # Get word embedding for distractor\n",
        "  distractor_embedding = model.get_word_vector(distractor)\n",
        "\n",
        "  # Calculate cosine similarity between golden label and distractor embeddings\n",
        "  golden_embedding = model.get_word_vector(\"numero ordinale\")\n",
        "  similarity = cosine_similarity(golden_embedding, distractor_embedding)\n",
        "  print('Cosine similarity: {:.2}'.format(similarity))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM9zDcnbL-ut"
      },
      "source": [
        "# 4.0 Create entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "QMejxfx46FGi"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def save_jsonl(file_path, model, num_distractors=3):\n",
        "    id_seq = 0\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            # Load JSON data from each line\n",
        "            data = json.loads(line)\n",
        "            \n",
        "            term = data['text']\n",
        "            hypernym = data['choices'][data['label']]\n",
        "            distractors = find_distractors(hypernym, num_distractors, model)\n",
        "            if hypernym not in distractors:\n",
        "                distractors.append(hypernym)\n",
        "            random.shuffle(distractors)\n",
        "            \n",
        "            # Create JSONL-formatted data\n",
        "            reformatted_json_data = {\n",
        "                'id': id_seq,\n",
        "                'text': term,\n",
        "                'choices': distractors,\n",
        "                'label': distractors.index(hypernym)\n",
        "            }\n",
        "            id_seq += 1\n",
        "            \n",
        "            # Write the reformatted data to the output file\n",
        "            with open('output.jsonl', 'a') as output_file:\n",
        "                json.dump(reformatted_json_data, output_file)\n",
        "                output_file.write('\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_lines_jsonl(file_path, num_lines):\n",
        "  with open(file_path, 'r') as f:\n",
        "    json_list = list(f)\n",
        "    for line in json_list[:num_lines]:\n",
        "      data = json.loads(line)\n",
        "      print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bfbw5MqpVqb",
        "outputId": "b6a2945e-d66f-4595-ba15-06b7af6cbc57"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msave_jsonl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhypernym_discovery-task26-train-data.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m read_lines_jsonl(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhypernym_discovery-task26-train-data.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_lines \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m) \u001b[38;5;66;03m# preview of the first 10 lines\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[45], line 27\u001b[0m, in \u001b[0;36msave_jsonl\u001b[1;34m(file_path, model, num_distractors)\u001b[0m\n\u001b[0;32m     24\u001b[0m id_seq \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Write the reformatted data to the output file\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput.jsonl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m output_file:\n\u001b[0;32m     28\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(reformatted_json_data, output_file)\n\u001b[0;32m     29\u001b[0m     output_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\_bootlocale.py:11\u001b[0m, in \u001b[0;36mgetpreferredencoding\u001b[1;34m(do_setlocale)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01m_locale\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetpreferredencoding\u001b[39m(do_setlocale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mutf8_mode:\n\u001b[0;32m     13\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUTF-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "save_jsonl(\"hypernym_discovery-task26-train-data.jsonl\", model)\n",
        "read_lines_jsonl(\"hypernym_discovery-task26-train-data.jsonl\", num_lines = 10) # preview of the first 10 lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoP2BcrhaQ_G",
        "outputId": "0515ae5b-a1de-4e73-c26c-540b1ef72ae0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.558272123336792"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = model.get_word_vector(\"grado\")\n",
        "b = model.get_word_vector(\"grado.\")\n",
        "cosine_similarity(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGJEipDX2L7s"
      },
      "outputs": [],
      "source": [
        "# test jsonl file\n",
        "save_jsonl(\"hypernym_discovery-task26-test-data.jsonl\", model)\n",
        "read_lines_jsonl(\"hypernym_discovery-task26-test-data.jsonl\", num_lines = 10) # preview of the first 10 lines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpnSwrev0jUA"
      },
      "source": [
        "# 5.0 Prompt formulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvgSvHol0mLk"
      },
      "outputs": [],
      "source": [
        "prompts = [\n",
        "    \"Il termine '{text}' può essere iperonimo di: \\n a) {option1} \\n b) {option2} \\n c) {option3} \\n d) {option4}\",\n",
        "    \"Dato il termine '{text}', quale tra le seguenti parole è un suo iperonimo? \\n a) {option1} \\n b) {option2} \\n c) {option3} \\n d) {option4}\",\n",
        "    \"Scegli l'iperonimo del termine '{text}': \\n a) {option1} \\n b) {option2} \\n c) {option3} \\n d) {option4}\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoZJb-dE7lkN"
      },
      "outputs": [],
      "source": [
        "print(' '.join(prompt + '\\n\\n' for prompt in prompts), end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqqCjLLSAUMy"
      },
      "outputs": [],
      "source": [
        "def save_prompts_jsonl(prompts, file_path):\n",
        "  json_prompts = []\n",
        "  for prompt in prompts:\n",
        "    json_prompts.append({\"prompt\": prompt})\n",
        "\n",
        "  with open(file_path, \"w\") as output_file:\n",
        "    for json_prompt in json_prompts:\n",
        "      json.dump(json_prompt, output_file)\n",
        "      output_file.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMnn5M3GBVOS"
      },
      "outputs": [],
      "source": [
        "save_prompts_jsonl(prompts, \"hypernym_discovery-task26-json.jsonl\")\n",
        "read_lines_jsonl(\"hypernym_discovery-task26-json.jsonl\", num_lines = 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0sLMr7iCJJy"
      },
      "source": [
        "# 6.0 Prompts Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31T-DzisjeHA",
        "outputId": "d5f41f9e-390c-47b1-ffe3-7d264d26c2e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31xt8WrSjhTH"
      },
      "outputs": [],
      "source": [
        "def evaluate_prompt(tokenizer, model, prompt, data_file, zero_shot_classification = False):\n",
        "  formatted_prompts, y_true, y_pred, score = [], [], [], []\n",
        "  lines = 0\n",
        "\n",
        "  with open(data_file, \"r\") as f:\n",
        "    json_data = list(f)\n",
        "    for line in json_data:\n",
        "      pair = json.loads(line)\n",
        "      id = pair['id']\n",
        "      text = pair['text']\n",
        "      choices = pair['choices']\n",
        "      label = pair['label']\n",
        "\n",
        "      formatted_prompt = prompt.format(text = text, option1 = choices[0], option2 = choices[1], option3 = choices[2], option4 = choices[3])\n",
        "      inputs = tokenizer([formatted_prompt] * len(choices), choices,\n",
        "                         padding = True, return_tensors = \"pt\").to(device)\n",
        "\n",
        "      if zero_shot_classification:\n",
        "        output = model(inputs, candidate_labels=choices, hypothesis_template=\"Questo esempio è {}.\")\n",
        "        predicted_output = output['labels'][0]\n",
        "        predicted_label = choices.index(predicted_output)\n",
        "        prediction_score = output['scores'][0]\n",
        "        lines += 1\n",
        "\n",
        "        if lines == 20:\n",
        "          break\n",
        "\n",
        "      else:\n",
        "        labels = torch.tensor(len(choices) - 1).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "          output = model(**{k: v.unsqueeze(0) for k, v in inputs.items()}, labels = labels)\n",
        "\n",
        "        probabilities = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
        "        predicted_label = np.argmax(probabilities)\n",
        "        prediction_score = probabilities[predicted_label]\n",
        "        lines += 1\n",
        "\n",
        "        if lines == 20:\n",
        "          break\n",
        "\n",
        "      formatted_prompts.append(formatted_prompt)\n",
        "      y_true.append(label)\n",
        "      y_pred.append(predicted_label)\n",
        "      score.append(prediction_score)\n",
        "\n",
        "    return formatted_prompts, y_true, y_pred, score\n",
        "\n",
        "\n",
        "def visualize_results(results, num_results):\n",
        "  for prompt in range(len(results)):\n",
        "    for n in range(num_results):\n",
        "      print(\"Prompt: \", results[prompt][0][n])\n",
        "      print(\"True label: \", results[prompt][1][n])\n",
        "      print(\"Predicted label: \", results[prompt][2][n])\n",
        "      print(\"Prediction score: \", round(results[prompt][3][n], 3))\n",
        "      print(\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beXPGvlB9MTB"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(y_true, y_pred):\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "  precision = precision_score(y_true, y_pred, average='weighted', zero_division=1)\n",
        "  recall = recall_score(y_true, y_pred, average='weighted', zero_division=1)\n",
        "  f1 = f1_score(y_true, y_pred, average='weighted', zero_division=1)\n",
        "  cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "  return accuracy, precision, recall, f1, cf_matrix\n",
        "\n",
        "\n",
        "def print_confusion_matrix(metrics, type):\n",
        "  for n in range(len(metrics)):\n",
        "    print(f\"{type} Confusion Matrix for the Prompt {n}\")\n",
        "    print(\"Prompt: \", prompts[n])\n",
        "\n",
        "    # Confusion Matrix Plot\n",
        "    cf_matrix = metrics[n][4]\n",
        "    fig, ax = plt.subplots(figsize=(5, 3))\n",
        "    sns.heatmap(cf_matrix, annot = True, fmt = '.0f')\n",
        "    ax.set_title('Confusion Matrix')\n",
        "    ax.set_xlabel('Predicted Labels')\n",
        "    ax.set_ylabel('True Labels')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Total Predictions: \", np.sum(cf_matrix))\n",
        "    print(\"Correct Predictions: \", np.trace(cf_matrix))\n",
        "    print(\"----------------------------------------------------------------\")\n",
        "    print(\" \")\n",
        "\n",
        "def print_overall_statistics(train_metrics, test_metrics, prompts):\n",
        "  comparison_table = []\n",
        "  for id, prompt in enumerate(prompts):\n",
        "    data = {}\n",
        "    for dtype, metrics in zip(['Train', 'Test'], [train_metrics, test_metrics]):\n",
        "      accuracy, precision, recall, f1, cf_matrix = metrics[id]\n",
        "      data[f'{dtype} Accuracy'] = round(accuracy, 3)\n",
        "      data[f'{dtype} Precision'] = round(precision, 3)\n",
        "      data[f'{dtype} Recall'] = round(recall, 3)\n",
        "      data[f'{dtype} F1-score'] = round(f1, 3)\n",
        "    comparison_table.append(data)\n",
        "  return pd.DataFrame(comparison_table).transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSHhbtQhQAXY"
      },
      "source": [
        "## 6.1 RoBERTa For Multiple Choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zq2H7HsuWse"
      },
      "outputs": [],
      "source": [
        "model_name = \"LIAMF-USP/roberta-large-finetuned-race\"\n",
        "roberta_tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "roberta_model = RobertaForMultipleChoice.from_pretrained(model_name).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so51vzKd8LnZ",
        "outputId": "dbc29402-342d-4b53-de1c-65c35dc7e1b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Execution Time:  1.9569334228833517 minutes\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "roberta_train_results, roberta_test_results = [], []\n",
        "\n",
        "for prompt in prompts:\n",
        "  formatted_prompt, y_true, y_pred, score = evaluate_prompt(roberta_tokenizer, roberta_model, prompt, \"hypernym_discovery-task26-train-data.jsonl\")\n",
        "  roberta_train_results.append([formatted_prompt, y_true, y_pred, score])\n",
        "\n",
        "  formatted_prompt, y_true, y_pred, score = evaluate_prompt(roberta_tokenizer, roberta_model, prompt, \"hypernym_discovery-task26-test-data.jsonl\")\n",
        "  roberta_test_results.append([formatted_prompt, y_true, y_pred, score])\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Execution Time: \", (end_time - start_time)/60, \"minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1oXAKZBsZ72"
      },
      "outputs": [],
      "source": [
        "visualize_results(roberta_train_results, num_results = 2) # preview of the first 2 train results for each prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfk8jfMDvyo3"
      },
      "outputs": [],
      "source": [
        "roberta_train_metrics, roberta_test_metrics = [], []\n",
        "\n",
        "for prompt in range(len(prompts)):\n",
        "  accuracy, precision, recall, f1, cf_matrix = compute_metrics(roberta_train_results[prompt][1], roberta_train_results[prompt][2])\n",
        "  roberta_train_metrics.append([accuracy, precision, recall, f1, cf_matrix])\n",
        "\n",
        "  accuracy, precision, recall, f1, cf_matrix = compute_metrics(roberta_test_results[prompt][1], roberta_test_results[prompt][2])\n",
        "  roberta_test_metrics.append([accuracy, precision, recall, f1, cf_matrix])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsNljtPY8PxS"
      },
      "source": [
        "### Overall Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mseiH-1S8RCE"
      },
      "outputs": [],
      "source": [
        "# Train Statistics for each prompt\n",
        "print_confusion_matrix(roberta_train_metrics, \"Train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8AfPh9T8S5A"
      },
      "outputs": [],
      "source": [
        "# Test Statistics for each prompt\n",
        "print_confusion_matrix(roberta_test_metrics, \"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-oflTOA8bFt"
      },
      "outputs": [],
      "source": [
        "print_overall_statistics(roberta_train_metrics, roberta_test_metrics, prompts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9YoFnhIcsEx"
      },
      "source": [
        "## 6.2 Zero Shot Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFeCM8kZSlRY"
      },
      "outputs": [],
      "source": [
        "classifier_names = [\"xlm-roberta-large\", \"facebook/bart-large-mnli\"]\n",
        "#roberta_classifier = pipeline(\"zero-shot-classification\", model=classifier_names[0], batch_size = 8, truncation=True, device = device)\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
        "bert_classifier = pipeline(\"zero-shot-classification\", model=classifier_names[1], batch_size = 8, truncation=True, device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wyqqRtO-51n",
        "outputId": "0a6a8bf0-0f79-4ec6-a3e0-e1907865f374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Execution Time:  0.9809847831726074 minutes\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "classifier_train_results, classifier_test_results = [], []\n",
        "\n",
        "for prompt in prompts:\n",
        "  formatted_prompt, y_true, y_pred, score = evaluate_prompt(bert_tokenizer, bert_classifier, prompt, \"hypernym_discovery-task26-train-data.jsonl\", True)\n",
        "  classifier_train_results.append([formatted_prompt, y_true, y_pred, score])\n",
        "\n",
        "  formatted_prompt, y_true, y_pred, score = evaluate_prompt(bert_tokenizer, bert_classifier, prompt, \"hypernym_discovery-task26-test-data.jsonl\", True)\n",
        "  classifier_test_results.append([formatted_prompt, y_true, y_pred, score])\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Execution Time: \", (end_time - start_time)/60, \"minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqIUvwZFhEHe"
      },
      "outputs": [],
      "source": [
        "visualize_results(classifier_train_results, num_results = 2) # preview of the first 2 train results for each prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PAkEwGFgBlH"
      },
      "outputs": [],
      "source": [
        "classifier_train_metrics, classifier_test_metrics = [], []\n",
        "\n",
        "for prompt in range(len(prompts)):\n",
        "  accuracy, precision, recall, f1, cf_matrix = compute_metrics(classifier_train_results[prompt][1], classifier_train_results[prompt][2])\n",
        "  classifier_train_metrics.append([accuracy, precision, recall, f1, cf_matrix])\n",
        "\n",
        "  accuracy, precision, recall, f1, cf_matrix = compute_metrics(classifier_test_results[prompt][1], classifier_test_results[prompt][2])\n",
        "  classifier_test_metrics.append([accuracy, precision, recall, f1, cf_matrix])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQSyzYZjuga5"
      },
      "source": [
        "### Overall Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixERGlZ4gYEW"
      },
      "outputs": [],
      "source": [
        "# Train Confusion Matrix for each prompt\n",
        "print_confusion_matrix(classifier_train_metrics, \"Train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qTYO4Yr3vOK"
      },
      "outputs": [],
      "source": [
        "# Test Statistics for each prompt\n",
        "print_confusion_matrix(classifier_test_metrics, \"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGF0DnMDkWHh"
      },
      "outputs": [],
      "source": [
        "print_overall_statistics(classifier_train_metrics, classifier_test_metrics, prompts)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

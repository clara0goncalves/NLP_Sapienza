{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0sPER-ui9HA"
      },
      "source": [
        "# 1.0 Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83qtMqTUka4o",
        "outputId": "a7f9eb6c-a8c7-45f7-f874-463329d80341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langid in /usr/local/lib/python3.10/dist-packages (1.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from langid) (1.25.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Collecting it-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.7.0/it_core_news_sm-3.7.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from it-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('it_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "--2024-04-04 23:05:15--  https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/50261113/52126080-0993-11ea-8190-8f0e295df22a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240404%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240404T230359Z&X-Amz-Expires=300&X-Amz-Signature=47116f7003e283c6a44e4cface904b08de556ab6673a24550be27216ef7f6f0a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50261113&response-content-disposition=attachment%3B%20filename%3Ds2v_reddit_2015_md.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-04-04 23:05:15--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/50261113/52126080-0993-11ea-8190-8f0e295df22a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240404%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240404T230359Z&X-Amz-Expires=300&X-Amz-Signature=47116f7003e283c6a44e4cface904b08de556ab6673a24550be27216ef7f6f0a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50261113&response-content-disposition=attachment%3B%20filename%3Ds2v_reddit_2015_md.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 600444501 (573M) [application/octet-stream]\n",
            "Saving to: ‘s2v_reddit_2015_md.tar.gz.3’\n",
            "\n",
            "s2v_reddit_2015_md. 100%[===================>] 572.63M   207MB/s    in 2.8s    \n",
            "\n",
            "2024-04-04 23:05:18 (207 MB/s) - ‘s2v_reddit_2015_md.tar.gz.3’ saved [600444501/600444501]\n",
            "\n",
            "./._s2v_old\n",
            "./s2v_old/\n",
            "./s2v_old/._freqs.json\n",
            "./s2v_old/freqs.json\n",
            "./s2v_old/._vectors\n",
            "./s2v_old/vectors\n",
            "./s2v_old/._cfg\n",
            "./s2v_old/cfg\n",
            "./s2v_old/._strings.json\n",
            "./s2v_old/strings.json\n",
            "./s2v_old/._key2row\n",
            "./s2v_old/key2row\n",
            "Requirement already satisfied: sense2vec in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from sense2vec) (3.7.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from sense2vec) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from sense2vec) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from sense2vec) (2.0.10)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from sense2vec) (1.25.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (8.2.3)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (3.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->sense2vec) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->sense2vec) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->sense2vec) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.0.0->sense2vec) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.0.0->sense2vec) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<4.0.0,>=3.0.0->sense2vec) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<4.0.0,>=3.0.0->sense2vec) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4.0.0,>=3.0.0->sense2vec) (2.1.5)\n",
            "Requirement already satisfied: spacy_fastlang in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: fasttext-wheel<0.10.0,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from spacy_fastlang) (0.9.2)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy_fastlang) (3.7.4)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->spacy_fastlang) (2.12.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->spacy_fastlang) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->spacy_fastlang) (1.25.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (3.1.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_fastlang) (3.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy_fastlang) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy_fastlang) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy_fastlang) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy_fastlang) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy_fastlang) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy_fastlang) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy_fastlang) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.0.0->spacy_fastlang) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.0.0->spacy_fastlang) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy_fastlang) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<4.0.0,>=3.0.0->spacy_fastlang) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4.0.0,>=3.0.0->spacy_fastlang) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install langid\n",
        "!pip install gensim\n",
        "!pip install -U spacy\n",
        "!python -m spacy download it_core_news_sm\n",
        "!wget https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
        "!tar -xzvf s2v_reddit_2015_md.tar.gz\n",
        "!pip install sense2vec\n",
        "!pip install spacy_fastlang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-3BMXNIjGo0",
        "outputId": "4f4029be-8466-4362-9d69-eb3f50431962"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import re\n",
        "import json\n",
        "import gensim.downloader as api\n",
        "\n",
        "import langid\n",
        "from gensim.models import Word2Vec\n",
        "import spacy\n",
        "import spacy_fastlang\n",
        "\n",
        "from sense2vec import Sense2Vec\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from transformers import RobertaTokenizer\n",
        "from transformers import RobertaForMultipleChoice\n",
        "from torch.distributions import Categorical\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWomv2Y0g-l_"
      },
      "source": [
        "# 2.0 Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "M9yPG6KyH1dx"
      },
      "outputs": [],
      "source": [
        "def load_data(data_path, gold_path):\n",
        "  count = 0\n",
        "  hypernyms_dict = {}\n",
        "  with open(data_path, \"r\", encoding = 'utf-8') as data_file, open(gold_path, \"r\", encoding = 'utf-8') as gold_file:\n",
        "    for data_line, gold_line in zip(data_file, gold_file):\n",
        "      term_list = [term for term in data_line.split()[:-1]]\n",
        "      term = \" \".join(term_list)\n",
        "      hypernyms = [hypernym.replace(\"\\n\", \"\") for hypernym in gold_line.split(\"\\t\")]\n",
        "      hypernyms_dict[term] = hypernyms\n",
        "      count += 1\n",
        "\n",
        "      if count == 20:\n",
        "        break\n",
        "\n",
        "  return hypernyms_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "oWNvGVp9XdIx"
      },
      "outputs": [],
      "source": [
        "#  PARTIAL italian training data\n",
        "train_hypernyms = load_data(\"/content/1B.italian.training.data.txt\", \"/content/1B.italian.training.gold.txt\")\n",
        "\n",
        "# PARTIAL italian test data\n",
        "test_hypernyms = load_data(\"/content/1B.italian.test.data.txt\", \"/content/1B.italian.test.gold.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff5gVEnfg6Lp"
      },
      "source": [
        "# 3.0 Find Distractors"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Fasttext\n"
      ],
      "metadata": {
        "id": "1SIts6mWLj_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "!cd fastText\n",
        "!sudo python setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHRYBJYpLpYi",
        "outputId": "12affec6-2bb2-425f-f3bd-0c1c250fbf15"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'fastText' already exists and is not an empty directory.\n",
            "python3: can't open file '/content/setup.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ],
      "metadata": {
        "id": "SVpKhfWuYzKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext.util\n",
        "# fasttext.util.download_model('it', if_exists='ignore')"
      ],
      "metadata": {
        "id": "K6SnidfZLq7S"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = fasttext.load_model('cc.it.300.bin')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xh530uT4Lwjn",
        "outputId": "a65e7903-4ede-4c6a-ae2d-64964387b926"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Function that calculates cosine similarity\n",
        "def cosine_similarity(embedding_1, embedding_2):\n",
        "    return 1 - cosine(embedding_1, embedding_2)\n",
        "\n",
        "\n",
        "def find_distractors(hypernym, num_distractors):\n",
        "  distractors = []\n",
        "\n",
        "  # Get word embedding for golden label\n",
        "  golden_embedding = model.get_word_vector(hypernym)\n",
        "\n",
        "  # Generate three distractors\n",
        "  candidates = model.get_nearest_neighbors(hypernym, k = 10)\n",
        "  for distractor in candidates:\n",
        "    distractor = distractor[1]\n",
        "    distractor_embedding = model.get_word_vector(distractor)\n",
        "    similarity = cosine_similarity(golden_embedding, distractor_embedding)\n",
        "    # Set the range threshold for the cosine similarity\n",
        "    if 0.1 <= similarity <= 0.6 and distractor not in distractors:\n",
        "      distractors.append(distractor)\n",
        "\n",
        "  return distractors[:num_distractors]"
      ],
      "metadata": {
        "id": "gz0eSEndRsz0"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example"
      ],
      "metadata": {
        "id": "WhD8vekoRgIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_nearest_neighbors('numero ordinale')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYnIStdDL1Is",
        "outputId": "6b156975-5570-487f-a0ba-7feba2b9fec2"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.69635009765625, 'dinale'),\n",
              " (0.6637539267539978, 'tecnicoeconomica'),\n",
              " (0.6575295329093933, 'numeroe'),\n",
              " (0.6210983991622925, 'ordinal'),\n",
              " (0.617618203163147, 'Ordinale'),\n",
              " (0.6075699925422668, 'Numeroordinale'),\n",
              " (0.6015861630439758, 'Numerocardinale'),\n",
              " (0.5819660425186157, 'estetologo'),\n",
              " (0.5808798670768738, 'Sindacatore'),\n",
              " (0.5799951553344727, 'anticardinale')]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_analogies(\"numero ordinale\", \"carinale\", \"millesimo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMYnnwyzL5n6",
        "outputId": "af942918-4bb0-4d08-e337-28e57ef7e214"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.4903110861778259, 'decimillesimo'),\n",
              " (0.46558308601379395, 'millesimi'),\n",
              " (0.430698961019516, 'duecentesimo'),\n",
              " (0.4299042224884033, 'ordinalità'),\n",
              " (0.4258556365966797, 'centesimo'),\n",
              " (0.421135812997818, 'decimo'),\n",
              " (0.4166191816329956, 'trecentesimo'),\n",
              " (0.40764376521110535, 'decimillesimi'),\n",
              " (0.4020084738731384, 'cinquantesimo'),\n",
              " (0.40015530586242676, 'milionesimo')]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distractors = find_distractors(\"numero ordinale\", num_distractors = 3)"
      ],
      "metadata": {
        "id": "JUOTCo9WRzwu"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, distractor in enumerate(distractors):\n",
        "  print(f\"Distractor {i + 1}: {distractor}\")\n",
        "\n",
        "  # Get word embedding for distractor\n",
        "  distractor_embedding = model.get_word_vector(distractor)\n",
        "\n",
        "  # Calculate cosine similarity between golden label and distractor embeddings\n",
        "  golden_embedding = model.get_word_vector(\"numero ordinale\")\n",
        "  similarity = cosine_similarity(golden_embedding, distractor_embedding)\n",
        "  print('Cosine similarity: {:.2}'.format(similarity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYZ0qhE8RkkU",
        "outputId": "70936007-18aa-4667-ca17-9b7117541c5c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distractor 1: estetologo\n",
            "Cosine similarity: 0.58\n",
            "Distractor 2: Sindacatore\n",
            "Cosine similarity: 0.58\n",
            "Distractor 3: anticardinale\n",
            "Cosine similarity: 0.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.0 Create entries"
      ],
      "metadata": {
        "id": "LM9zDcnbL-ut"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "QMejxfx46FGi"
      },
      "outputs": [],
      "source": [
        "def save_jsonl(file_path, data):\n",
        "  id_seq = 0\n",
        "  with open(file_path, \"w\") as output_file:\n",
        "    for term, hypernyms in data.items():\n",
        "      for hypernym in hypernyms:\n",
        "        distractors = find_distractors(hypernym, num_distractors = 3)\n",
        "        entries = (hypernym, *distractors)\n",
        "        choices = list(entries)\n",
        "        random.shuffle(choices) # to create randomness\n",
        "        reformatted_json_data = {\n",
        "              'id' : id_seq,\n",
        "              'text': term,\n",
        "              'choices': choices,\n",
        "              'label' : choices.index(hypernym)\n",
        "        }\n",
        "        json.dump(reformatted_json_data, output_file)\n",
        "        output_file.write(\"\\n\")\n",
        "        id_seq +=1\n",
        "\n",
        "def read_lines_jsonl(file_path, num_lines):\n",
        "  with open(file_path, 'r') as f:\n",
        "    json_list = list(f)\n",
        "    for line in json_list[:num_lines]:\n",
        "      data = json.loads(line)\n",
        "      print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bfbw5MqpVqb",
        "outputId": "b6a2945e-d66f-4595-ba15-06b7af6cbc57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 0, 'text': 'sesto', 'choices': ['grado', 'grado.', 'ingrado', 'poter'], 'label': 0}\n",
            "{'id': 1, 'text': 'sesto', 'choices': ['anticardinale', 'numero ordinale', 'estetologo', 'Sindacatore'], 'label': 1}\n",
            "{'id': 2, 'text': 'sesto', 'choices': ['frazione', 'frazionale', '-frazione', 'ex-frazione'], 'label': 0}\n",
            "{'id': 3, 'text': 'sesto', 'choices': ['cariche', 'carica.La', 'ricoperta', 'carica'], 'label': 3}\n",
            "{'id': 4, 'text': 'Sigillo', 'choices': ['denominatore', 'comune', 'comunee', 'comune.Il'], 'label': 1}\n",
            "{'id': 5, 'text': 'Sigillo', 'choices': ['Principalità', 'città-provincia', 'municipalità', 'Municipalities'], 'label': 2}\n",
            "{'id': 6, 'text': 'Sigillo', 'choices': ['comunee', 'monale', 'ComuneAlba', 'comune italiano'], 'label': 3}\n",
            "{'id': 7, 'text': 'Sigillo', 'choices': ['-frazione', 'frazionale', 'ex-frazione', 'frazione'], 'label': 3}\n",
            "{'id': 8, 'text': 'Sigillo', 'choices': ['paese'], 'label': 0}\n",
            "{'id': 9, 'text': 'Sigillo', 'choices': ['quartiere'], 'label': 0}\n"
          ]
        }
      ],
      "source": [
        "# train jsonl file\n",
        "save_jsonl(\"hypernym_discovery-task26-train-data.jsonl\", train_hypernyms)\n",
        "read_lines_jsonl(\"hypernym_discovery-task26-train-data.jsonl\", num_lines = 10) # preview of the first 10 lines"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = model.get_word_vector(\"grado\")\n",
        "b = model.get_word_vector(\"grado.\")\n",
        "cosine_similarity(a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoP2BcrhaQ_G",
        "outputId": "0515ae5b-a1de-4e73-c26c-540b1ef72ae0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.558272123336792"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGJEipDX2L7s"
      },
      "outputs": [],
      "source": [
        "# test jsonl file\n",
        "save_jsonl(\"hypernym_discovery-task26-test-data.jsonl\", test_hypernyms)\n",
        "read_lines_jsonl(\"hypernym_discovery-task26-test-data.jsonl\", num_lines = 10) # preview of the first 10 lines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpnSwrev0jUA"
      },
      "source": [
        "# 5.0 Prompt formulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvgSvHol0mLk"
      },
      "outputs": [],
      "source": [
        "prompts = [\n",
        "    \"Il termine '{text}' può essere iperonimo di: \\n a) {option1} \\n b) {option2} \\n c) {option3} \\n d) {option4}\",\n",
        "    \"Dato il termine '{text}', quale tra le seguenti parole è un suo iperonimo? \\n a) {option1} \\n b) {option2} \\n c) {option3} \\n d) {option4}\",\n",
        "    \"Scegli l'iperonimo del termine '{text}': \\n a) {option1} \\n b) {option2} \\n c) {option3} \\n d) {option4}\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(' '.join(prompt + '\\n\\n' for prompt in prompts), end='')"
      ],
      "metadata": {
        "id": "yoZJb-dE7lkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqqCjLLSAUMy"
      },
      "outputs": [],
      "source": [
        "def save_prompts_jsonl(prompts, file_path):\n",
        "  json_prompts = []\n",
        "  for prompt in prompts:\n",
        "    json_prompts.append({\"prompt\": prompt})\n",
        "\n",
        "  with open(file_path, \"w\") as output_file:\n",
        "    for json_prompt in json_prompts:\n",
        "      json.dump(json_prompt, output_file)\n",
        "      output_file.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMnn5M3GBVOS"
      },
      "outputs": [],
      "source": [
        "save_prompts_jsonl(prompts, \"hypernym_discovery-task26-json.jsonl\")\n",
        "read_lines_jsonl(\"hypernym_discovery-task26-json.jsonl\", num_lines = 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0sLMr7iCJJy"
      },
      "source": [
        "# 6.0 Prompts Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31T-DzisjeHA",
        "outputId": "d5f41f9e-390c-47b1-ffe3-7d264d26c2e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31xt8WrSjhTH"
      },
      "outputs": [],
      "source": [
        "def evaluate_prompt(tokenizer, model, prompt, data_file, zero_shot_classification = False):\n",
        "  formatted_prompts, y_true, y_pred, score = [], [], [], []\n",
        "  lines = 0\n",
        "\n",
        "  with open(data_file, \"r\") as f:\n",
        "    json_data = list(f)\n",
        "    for line in json_data:\n",
        "      pair = json.loads(line)\n",
        "      id = pair['id']\n",
        "      text = pair['text']\n",
        "      choices = pair['choices']\n",
        "      label = pair['label']\n",
        "\n",
        "      formatted_prompt = prompt.format(text = text, option1 = choices[0], option2 = choices[1], option3 = choices[2], option4 = choices[3])\n",
        "      inputs = tokenizer([formatted_prompt] * len(choices), choices,\n",
        "                         padding = True, return_tensors = \"pt\").to(device)\n",
        "\n",
        "      if zero_shot_classification:\n",
        "        output = model(inputs, candidate_labels=choices, hypothesis_template=\"Questo esempio è {}.\")\n",
        "        predicted_output = output['labels'][0]\n",
        "        predicted_label = choices.index(predicted_output)\n",
        "        prediction_score = output['scores'][0]\n",
        "        lines += 1\n",
        "\n",
        "        if lines == 20:\n",
        "          break\n",
        "\n",
        "      else:\n",
        "        labels = torch.tensor(len(choices) - 1).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "          output = model(**{k: v.unsqueeze(0) for k, v in inputs.items()}, labels = labels)\n",
        "\n",
        "        probabilities = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
        "        predicted_label = np.argmax(probabilities)\n",
        "        prediction_score = probabilities[predicted_label]\n",
        "        lines += 1\n",
        "\n",
        "        if lines == 20:\n",
        "          break\n",
        "\n",
        "      formatted_prompts.append(formatted_prompt)\n",
        "      y_true.append(label)\n",
        "      y_pred.append(predicted_label)\n",
        "      score.append(prediction_score)\n",
        "\n",
        "    return formatted_prompts, y_true, y_pred, score\n",
        "\n",
        "\n",
        "def visualize_results(results, num_results):\n",
        "  for prompt in range(len(results)):\n",
        "    for n in range(num_results):\n",
        "      print(\"Prompt: \", results[prompt][0][n])\n",
        "      print(\"True label: \", results[prompt][1][n])\n",
        "      print(\"Predicted label: \", results[prompt][2][n])\n",
        "      print(\"Prediction score: \", round(results[prompt][3][n], 3))\n",
        "      print(\" \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(y_true, y_pred):\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "  precision = precision_score(y_true, y_pred, average='weighted', zero_division=1)\n",
        "  recall = recall_score(y_true, y_pred, average='weighted', zero_division=1)\n",
        "  f1 = f1_score(y_true, y_pred, average='weighted', zero_division=1)\n",
        "  cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "  return accuracy, precision, recall, f1, cf_matrix\n",
        "\n",
        "\n",
        "def print_confusion_matrix(metrics, type):\n",
        "  for n in range(len(metrics)):\n",
        "    print(f\"{type} Confusion Matrix for the Prompt {n}\")\n",
        "    print(\"Prompt: \", prompts[n])\n",
        "\n",
        "    # Confusion Matrix Plot\n",
        "    cf_matrix = metrics[n][4]\n",
        "    fig, ax = plt.subplots(figsize=(5, 3))\n",
        "    sns.heatmap(cf_matrix, annot = True, fmt = '.0f')\n",
        "    ax.set_title('Confusion Matrix')\n",
        "    ax.set_xlabel('Predicted Labels')\n",
        "    ax.set_ylabel('True Labels')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Total Predictions: \", np.sum(cf_matrix))\n",
        "    print(\"Correct Predictions: \", np.trace(cf_matrix))\n",
        "    print(\"----------------------------------------------------------------\")\n",
        "    print(\" \")\n",
        "\n",
        "def print_overall_statistics(train_metrics, test_metrics, prompts):\n",
        "  comparison_table = []\n",
        "  for id, prompt in enumerate(prompts):\n",
        "    data = {}\n",
        "    for dtype, metrics in zip(['Train', 'Test'], [train_metrics, test_metrics]):\n",
        "      accuracy, precision, recall, f1, cf_matrix = metrics[id]\n",
        "      data[f'{dtype} Accuracy'] = round(accuracy, 3)\n",
        "      data[f'{dtype} Precision'] = round(precision, 3)\n",
        "      data[f'{dtype} Recall'] = round(recall, 3)\n",
        "      data[f'{dtype} F1-score'] = round(f1, 3)\n",
        "    comparison_table.append(data)\n",
        "  return pd.DataFrame(comparison_table).transpose()"
      ],
      "metadata": {
        "id": "beXPGvlB9MTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSHhbtQhQAXY"
      },
      "source": [
        "## 6.1 RoBERTa For Multiple Choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zq2H7HsuWse"
      },
      "outputs": [],
      "source": [
        "model_name = \"LIAMF-USP/roberta-large-finetuned-race\"\n",
        "roberta_tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "roberta_model = RobertaForMultipleChoice.from_pretrained(model_name).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "roberta_train_results, roberta_test_results = [], []\n",
        "\n",
        "for prompt in prompts:\n",
        "  formatted_prompt, y_true, y_pred, score = evaluate_prompt(roberta_tokenizer, roberta_model, prompt, \"hypernym_discovery-task26-train-data.jsonl\")\n",
        "  roberta_train_results.append([formatted_prompt, y_true, y_pred, score])\n",
        "\n",
        "  formatted_prompt, y_true, y_pred, score = evaluate_prompt(roberta_tokenizer, roberta_model, prompt, \"hypernym_discovery-task26-test-data.jsonl\")\n",
        "  roberta_test_results.append([formatted_prompt, y_true, y_pred, score])\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Execution Time: \", (end_time - start_time)/60, \"minutes\")"
      ],
      "metadata": {
        "id": "so51vzKd8LnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbc29402-342d-4b53-de1c-65c35dc7e1b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time:  1.9569334228833517 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1oXAKZBsZ72"
      },
      "outputs": [],
      "source": [
        "visualize_results(roberta_train_results, num_results = 2) # preview of the first 2 train results for each prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfk8jfMDvyo3"
      },
      "outputs": [],
      "source": [
        "roberta_train_metrics, roberta_test_metrics = [], []\n",
        "\n",
        "for prompt in range(len(prompts)):\n",
        "  accuracy, precision, recall, f1, cf_matrix = compute_metrics(roberta_train_results[prompt][1], roberta_train_results[prompt][2])\n",
        "  roberta_train_metrics.append([accuracy, precision, recall, f1, cf_matrix])\n",
        "\n",
        "  accuracy, precision, recall, f1, cf_matrix = compute_metrics(roberta_test_results[prompt][1], roberta_test_results[prompt][2])\n",
        "  roberta_test_metrics.append([accuracy, precision, recall, f1, cf_matrix])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overall Statistics"
      ],
      "metadata": {
        "id": "qsNljtPY8PxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Statistics for each prompt\n",
        "print_confusion_matrix(roberta_train_metrics, \"Train\")"
      ],
      "metadata": {
        "id": "mseiH-1S8RCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Statistics for each prompt\n",
        "print_confusion_matrix(roberta_test_metrics, \"Test\")"
      ],
      "metadata": {
        "id": "g8AfPh9T8S5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_overall_statistics(roberta_train_metrics, roberta_test_metrics, prompts)"
      ],
      "metadata": {
        "id": "M-oflTOA8bFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 Zero Shot Text Classification"
      ],
      "metadata": {
        "id": "Y9YoFnhIcsEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_names = [\"xlm-roberta-large\", \"facebook/bart-large-mnli\"]\n",
        "#roberta_classifier = pipeline(\"zero-shot-classification\", model=classifier_names[0], batch_size = 8, truncation=True, device = device)\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
        "bert_classifier = pipeline(\"zero-shot-classification\", model=classifier_names[1], batch_size = 8, truncation=True, device = device)"
      ],
      "metadata": {
        "id": "KFeCM8kZSlRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "classifier_train_results, classifier_test_results = [], []\n",
        "\n",
        "for prompt in prompts:\n",
        "  formatted_prompt, y_true, y_pred, score = evaluate_prompt(bert_tokenizer, bert_classifier, prompt, \"hypernym_discovery-task26-train-data.jsonl\", True)\n",
        "  classifier_train_results.append([formatted_prompt, y_true, y_pred, score])\n",
        "\n",
        "  formatted_prompt, y_true, y_pred, score = evaluate_prompt(bert_tokenizer, bert_classifier, prompt, \"hypernym_discovery-task26-test-data.jsonl\", True)\n",
        "  classifier_test_results.append([formatted_prompt, y_true, y_pred, score])\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Execution Time: \", (end_time - start_time)/60, \"minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a6a8bf0-0f79-4ec6-a3e0-e1907865f374",
        "id": "-wyqqRtO-51n"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time:  0.9809847831726074 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_results(classifier_train_results, num_results = 2) # preview of the first 2 train results for each prompt"
      ],
      "metadata": {
        "id": "fqIUvwZFhEHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_train_metrics, classifier_test_metrics = [], []\n",
        "\n",
        "for prompt in range(len(prompts)):\n",
        "  accuracy, precision, recall, f1, cf_matrix = compute_metrics(classifier_train_results[prompt][1], classifier_train_results[prompt][2])\n",
        "  classifier_train_metrics.append([accuracy, precision, recall, f1, cf_matrix])\n",
        "\n",
        "  accuracy, precision, recall, f1, cf_matrix = compute_metrics(classifier_test_results[prompt][1], classifier_test_results[prompt][2])\n",
        "  classifier_test_metrics.append([accuracy, precision, recall, f1, cf_matrix])"
      ],
      "metadata": {
        "id": "_PAkEwGFgBlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overall Statistics"
      ],
      "metadata": {
        "id": "wQSyzYZjuga5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Confusion Matrix for each prompt\n",
        "print_confusion_matrix(classifier_train_metrics, \"Train\")"
      ],
      "metadata": {
        "id": "ixERGlZ4gYEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Statistics for each prompt\n",
        "print_confusion_matrix(classifier_test_metrics, \"Test\")"
      ],
      "metadata": {
        "id": "_qTYO4Yr3vOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_overall_statistics(classifier_train_metrics, classifier_test_metrics, prompts)"
      ],
      "metadata": {
        "id": "UGF0DnMDkWHh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
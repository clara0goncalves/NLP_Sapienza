{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0sPER-ui9HA"
      },
      "source": [
        "# 1.0 Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83qtMqTUka4o",
        "outputId": "0d7dd377-4b60-4f73-a192-4f4b778da2dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langid in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.1.6)\n",
            "Requirement already satisfied: numpy in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langid) (1.26.0)\n",
            "Requirement already satisfied: gensim in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gensim) (1.26.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gensim) (1.11.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gensim) (6.4.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\runpy.py\", line 188, in _run_module_as_main\n",
            "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\runpy.py\", line 147, in _get_module_details\n",
            "    return _get_module_details(pkg_main_name, error)\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\runpy.py\", line 111, in _get_module_details\n",
            "    __import__(pkg_name)\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\spacy\\__init__.py\", line 13, in <module>\n",
            "    from . import pipeline  # noqa: F401\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\spacy\\pipeline\\__init__.py\", line 1, in <module>\n",
            "    from .attributeruler import AttributeRuler\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\spacy\\pipeline\\attributeruler.py\", line 8, in <module>\n",
            "    from ..language import Language\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\spacy\\language.py\", line 43, in <module>\n",
            "    from .pipe_analysis import analyze_pipes, print_pipe_analysis, validate_attrs\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\spacy\\pipe_analysis.py\", line 6, in <module>\n",
            "    from .tokens import Doc, Span, Token\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\spacy\\tokens\\__init__.py\", line 1, in <module>\n",
            "    from ._serialize import DocBin\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\spacy\\tokens\\_serialize.py\", line 14, in <module>\n",
            "    from ..vocab import Vocab\n",
            "  File \"spacy\\vocab.pyx\", line 1, in init spacy.vocab\n",
            "  File \"spacy\\tokens\\doc.pyx\", line 49, in init spacy.tokens.doc\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\site-packages\\spacy\\schemas.py\", line 287, in <module>\n",
            "    class TokenPattern(BaseModel):\n",
            "  File \"pydantic\\main.py\", line 299, in pydantic.main.ModelMetaclass.__new__\n",
            "  File \"pydantic\\fields.py\", line 411, in pydantic.fields.ModelField.infer\n",
            "  File \"pydantic\\fields.py\", line 342, in pydantic.fields.ModelField.__init__\n",
            "  File \"pydantic\\fields.py\", line 451, in pydantic.fields.ModelField.prepare\n",
            "  File \"pydantic\\fields.py\", line 545, in pydantic.fields.ModelField._type_analysis\n",
            "  File \"pydantic\\fields.py\", line 550, in pydantic.fields.ModelField._type_analysis\n",
            "  File \"c:\\Users\\35193\\miniconda3\\envs\\cuda_env\\lib\\typing.py\", line 852, in __subclasscheck__\n",
            "    return issubclass(cls, self.__origin__)\n",
            "TypeError: issubclass() arg 1 must be a class\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langdetect in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.0.9)\n",
            "Requirement already satisfied: six in c:\\users\\35193\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from langdetect) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langid\n",
        "!pip install gensim\n",
        "#!pip install -U spacy\n",
        "!python -m spacy download it_core_news_sm\n",
        "!pip install langdetect\n",
        "# !wget https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
        "# !tar -xzvf s2v_reddit_2015_md.tar.gz\n",
        "# !pip install sense2vec\n",
        "#!pip install spacy_fastlang\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njTlJZWDaLSL"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-3BMXNIjGo0",
        "outputId": "4cf31533-38f8-483b-b95c-45e4840ca785"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "import re\n",
        "import json\n",
        "import gensim.downloader as api\n",
        "\n",
        "import langid\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import random\n",
        "\n",
        "import torch\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "# import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import nltk\n",
        "# nltk.download('omw-1.4')\n",
        "# nltk.download('wordnet')\n",
        "# from nltk.corpus import wordnet as wn\n",
        "\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWomv2Y0g-l_"
      },
      "source": [
        "# 2.0 Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8djnrRqluH-7"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M9yPG6KyH1dx"
      },
      "outputs": [],
      "source": [
        "def load_data(data_path, gold_path):\n",
        "  count = 0\n",
        "  hypernyms_dict = {}\n",
        "  with open(data_path, \"r\", encoding = 'utf-8') as data_file, open(gold_path, \"r\", encoding = 'utf-8') as gold_file:\n",
        "    for data_line, gold_line in zip(data_file, gold_file):\n",
        "      term_list = [term for term in data_line.split()[:-1]]\n",
        "      term = \" \".join(term_list)\n",
        "      hypernyms = [hypernym.replace(\"\\n\", \"\") for hypernym in gold_line.split(\"\\t\")]\n",
        "      hypernyms_dict[term] = hypernyms\n",
        "      count += 1\n",
        "\n",
        "      if count == 20:\n",
        "        break\n",
        "\n",
        "  return hypernyms_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oWNvGVp9XdIx"
      },
      "outputs": [],
      "source": [
        "# path = \"/content/gdrive/MyDrive/\"\n",
        "\n",
        "#  PARTIAL italian training data\n",
        "train_hypernyms = load_data(\"1B.italian.training.data.txt\", \"1B.italian.training.gold.txt\")\n",
        "\n",
        "# PARTIAL italian test data\n",
        "test_hypernyms = load_data(\"1B.italian.test.data.txt\", \"1B.italian.test.gold.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzNMIkBleI8O",
        "outputId": "67ffca0a-da3b-4693-ba1a-f876f3c968bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sesto': ['grado', 'numero ordinale', 'frazione', 'carica'], 'Sigillo': ['comune', 'municipalità', 'comune italiano', 'frazione', 'paese', 'quartiere', 'comunità', 'borgo'], 'toga': ['comune', 'mantella', 'indumento', 'vestito', 'mantello', 'veste', 'abito', 'costume'], 'Eduard Buchner': ['accademico', 'persona', 'professore', 'biochimico', 'scienziato', 'chimico', 'scopritore', 'docente'], 'montagna': ['panorama', 'grande quantità', 'rilievo'], 'Renato Guttuso': ['pittore', 'persona', 'artista', 'politico'], 'cardamomo': ['pianta', 'aroma', 'tracheobionta', 'vegetale', 'pianta da fiore', 'magnoliophyta'], 'musical': ['rappresentazione', 'spettacolo', 'spettacolo teatrale', 'show'], 'vicino': ['persona'], 'rinnovo': ['sostituzione', 'prosieguo', 'proroga', 'proseguimento', 'replica', 'continuamento', 'prosecuzione'], 'rampollo': ['parente', 'congiunto', 'persona', 'famigliare'], 'piccione': ['uccello', 'animale', 'volatile', 'vertebrato'], 'cernita': ['comune'], 'gettone': ['dischetto', 'moneta', 'compenso', 'disco', 'cerchio'], 'Riunione': ['isola'], 'fondo': ['zona', 'barriera', 'estremità', 'gara', 'limite', 'competizione', 'località', 'sport olimpico', 'sportivo'], 'nomignolo': ['nome in codice', 'denominazione', 'antroponimo', 'nominativo', 'nome di battesimo'], 'straniero': ['viaggiatore', 'equus'], 'bando': ['concorso', 'documento'], 'ottobre': ['periodo', 'mese civile', 'tempo', 'mese', 'periodo di tempo']}\n"
          ]
        }
      ],
      "source": [
        "print(train_hypernyms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSwdInpWaDlC"
      },
      "source": [
        "#Generate Distractors from italian dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xSi-aDxvgvG",
        "outputId": "0e259b1e-431f-4d57-ebd8-5e08394de8e8"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/napolux/paroleitaliane.git\n",
        "# %cd /content/Parole_Italiane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy-yrypF3ZhV",
        "outputId": "1967cd15-cdf9-4a5f-cef6-7552394d460a"
      },
      "outputs": [],
      "source": [
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.it.300.bin.gz\n",
        "# !gunzip cc.it.300.bin.gz\n",
        "# !pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Un1DCEFSv91T"
      },
      "outputs": [],
      "source": [
        "with open('280000_parole_italiane.txt', 'r') as file:\n",
        "  italian_word_list=[]\n",
        "  for line in file:\n",
        "    italian_word_list.append(line)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oQnZBa8aIYp8"
      },
      "outputs": [],
      "source": [
        "import fasttext\n",
        "import numpy as np\n",
        "import fasttext.util\n",
        "\n",
        "def cosine_similarity(v1, v2):\n",
        "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
        "\n",
        "def check_letter(word1, word2):\n",
        "\n",
        "    common_letters = set(word1).intersection(set(word2))\n",
        "\n",
        "    threshold = len(word1) * 0.4\n",
        "\n",
        "    if len(common_letters) >= threshold:\n",
        "        return False\n",
        "    else:\n",
        "        return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "juHQ1nWuSdEL"
      },
      "outputs": [],
      "source": [
        "def compute_embeddings(italian_word_list, model):\n",
        "  word_list = italian_word_list\n",
        "  embedding_words = []\n",
        "\n",
        "  for word in word_list:\n",
        "      word_vector = model.get_word_vector(word)\n",
        "      embedding_words.append(word_vector)\n",
        "\n",
        "  return embedding_words\n",
        "\n",
        "embedding_list = compute_embeddings(italian_word_list, ft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h7NKDqnwe7r",
        "outputId": "ae09671b-d9d1-460a-b603-ddd906179355"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['pappagallo', 'iguana', 'bufaga']\n"
          ]
        }
      ],
      "source": [
        "def find_distractors(italian_word_list, embedding_list ,target_word, number, model):\n",
        "\n",
        "  target_vector = model.get_word_vector(target_word)\n",
        "\n",
        "  word_list = italian_word_list\n",
        "  similar_words = []\n",
        "  th = 0.5\n",
        "\n",
        "  while(len(similar_words)< number):\n",
        "    similar_words = []\n",
        "    for i, embed in enumerate(embedding_list):\n",
        "        similarity = cosine_similarity(target_vector, embed)\n",
        "\n",
        "        if similarity > th and check_letter(target_word, word_list[i]):\n",
        "            similar_words.append(word_list[i].replace('\\n', ''))\n",
        "\n",
        "    th = th - 0.025\n",
        "\n",
        "\n",
        "  results = []\n",
        "  while(len(results)<3):\n",
        "    index = random.randint(0, len(similar_words)-1)\n",
        "    if similar_words[index] not in(results):\n",
        "      results.append(similar_words[index])\n",
        "\n",
        "  return results\n",
        "\n",
        "\n",
        "ft = fasttext.load_model('cc.it.300.bin')\n",
        "\n",
        "print(find_distractors(italian_word_list, embedding_list, \"uccello\", 3 ,ft))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrVfLz1PfhW0"
      },
      "source": [
        "# 4.0 Create entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gTqI8KUffhXC"
      },
      "outputs": [],
      "source": [
        "def save_jsonl(file_path, data, model, italian_word_list, embedding_list):\n",
        "  id_seq = 0\n",
        "  with open(file_path, \"w\") as output_file:\n",
        "    for term, hypernyms in data.items():\n",
        "      for hypernym in hypernyms:\n",
        "        distractors = find_distractors(italian_word_list,embedding_list, hypernym, 3, model)\n",
        "        entries = (hypernym, *distractors)\n",
        "        choices = list(entries)\n",
        "        random.shuffle(choices)\n",
        "        reformatted_json_data = {\n",
        "              'id' : id_seq,\n",
        "              'text': term,\n",
        "              'choices': choices,\n",
        "              'label' : choices.index(hypernym)\n",
        "        }\n",
        "        json.dump(reformatted_json_data, output_file)\n",
        "        output_file.write(\"\\n\")\n",
        "        id_seq +=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Z6Shi9fpfhXD"
      },
      "outputs": [],
      "source": [
        "def read_lines_jsonl(file_path, num_lines):\n",
        "  with open(file_path, 'r') as f:\n",
        "    json_list = list(f)\n",
        "    for line in json_list[:num_lines]:\n",
        "      data = json.loads(line)\n",
        "      print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "BNV_KnfpfhXD",
        "outputId": "15116cb3-e29d-44a1-da53-e8a49def9ae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': 0, 'text': 'sesto', 'choices': ['capaci', 'potei', 'smettere', 'grado'], 'label': 3}\n",
            "{'id': 1, 'text': 'sesto', 'choices': ['numero ordinale', 'modelle', 'paesaggistica', 'misteri'], 'label': 0}\n",
            "{'id': 2, 'text': 'sesto', 'choices': ['frazione', 'borgatara', 'borgata', 'cascinai'], 'label': 0}\n",
            "{'id': 3, 'text': 'sesto', 'choices': ['pompavo', 'carica', 'simbolismo', 'passione'], 'label': 1}\n",
            "{'id': 4, 'text': 'Sigillo', 'choices': ['comune', 'frazionisti', 'paesello', 'regima'], 'label': 0}\n",
            "{'id': 5, 'text': 'Sigillo', 'choices': ['provincie', 'municipalità', 'stazione', 'distretti'], 'label': 1}\n",
            "{'id': 6, 'text': 'Sigillo', 'choices': ['salmastrati', 'comune italiano', 'floristico', 'tetraone'], 'label': 1}\n",
            "{'id': 7, 'text': 'Sigillo', 'choices': ['rocca', 'borgatara', 'frazione', 'borgata'], 'label': 2}\n",
            "{'id': 8, 'text': 'Sigillo', 'choices': ['paese', 'villaggi', 'mondo', 'nord'], 'label': 0}\n",
            "{'id': 9, 'text': 'Sigillo', 'choices': ['ghettoni', 'campus', 'rione', 'quartiere'], 'label': 3}\n"
          ]
        }
      ],
      "source": [
        "save_jsonl(\"hypernym_discovery-task26-train-data.jsonl\", train_hypernyms, ft, italian_word_list, embedding_list)\n",
        "read_lines_jsonl(\"hypernym_discovery-task26-train-data.jsonl\", num_lines = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "xijL3kpEfhXE"
      },
      "outputs": [],
      "source": [
        "save_jsonl(\"hypernym_discovery-task26-test-data.jsonl\", train_hypernyms, ft, italian_word_list, embedding_list)\n",
        "read_lines_jsonl(\"hypernym_discovery-task26-test-data.jsonl\", num_lines = 10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
